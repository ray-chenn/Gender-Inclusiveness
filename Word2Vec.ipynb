{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1020,
   "id": "701b8b8a-5bf0-4c57-901b-32d6f73d27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "0948688b-a7e3-439c-a605-35d9dcbeeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.read().replace('\\n',' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "d0cdb67f-86e6-4d47-bce9-7b9fb4c45d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 0\n",
    "stopwords = []\n",
    "#remove double quotation marks and citations/references if any\n",
    "with open('training_text.txt') as f1, open('stopwords.txt') as f2:\n",
    "    for line2 in f2:\n",
    "        for word in line2.split():\n",
    "            stopwords.append(word)\n",
    "    for line1 in f1:\n",
    "        for word in line1.split():\n",
    "            if (word) not in L:\n",
    "                words += 1\n",
    "\n",
    "words - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "d6395154-c707-404b-b688-74b77c9b55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the following text for words pertaining to masculinity and femininity : Selection of appropriate software plays a vital role in facilitatingchildren’s desire to use computers. The discrepancybetween girls’ and boys’ use of computers is enhanced by thescarcity of gender bias-free software programs. Analysis ofthe extant literature and rating of children’s software indicatesthat gender bias is reflected in terms of characters, contentand reward systems in the software program. A checklistis developed and pretested in this article. This checklist canbe used to generate awareness of the subtle but pervasivegender bias in children’s software programs and can be usedby teachers in the selection and use of appropriate softwareprograms in their classrooms.\n"
     ]
    }
   ],
   "source": [
    "with open('training_text.txt', encoding='utf-8') as f:\n",
    "    word = 0\n",
    "    text = f.read().replace('\\n','')\n",
    "    print(text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ''.join([t for t in text if t not in list('0123456789')])\n",
    "    text = text.replace('”', '').replace('“', '').replace('’', '').lower().split()\n",
    "\n",
    "text = [w for w in text if w not in stopwords][:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "7f8882cf-439c-4999-917e-18f5bef6bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "NUM_NEGATIVE_SAMPLES = 3\n",
    "\n",
    "data = []\n",
    "\n",
    "#iterate over all words\n",
    "for idx,center_word in enumerate(text[WINDOW_SIZE-1:-WINDOW_SIZE]):\n",
    "    \n",
    "    #iterate over the context words around the center word\n",
    "    context_words = [context_word for context_word in text[idx:idx+2*WINDOW_SIZE-1] if context_word != center_word]\n",
    "    for context_word in context_words:\n",
    "        \n",
    "        #get words NOT in the current context as negative examples\n",
    "        data.append([center_word, context_word, 1])\n",
    "        negative_samples = np.random.choice([w for w in text[WINDOW_SIZE-1:-WINDOW_SIZE] if w != center_word and w not in context_words], NUM_NEGATIVE_SAMPLES)\n",
    "        \n",
    "        for negative_samp in negative_samples:\n",
    "            \n",
    "            #add a training row\n",
    "            data.append([center_word, negative_samp, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "a565db41-6260-4049-9052-d1df80312a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['center_word', 'context_word', 'label'], data=data)\n",
    "words = np.intersect1d(df.context_word, df.center_word)\n",
    "df = df[(df.center_word.isin(words)) & (df.context_word.isin(words))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "9647b3b0-1057-4258-9fda-d3792ca8d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v, scale=1):\n",
    "    return 1 / (1 + np.exp(-scale*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "7ca43bfd-07ab-4564-8d85-4ec0b70e8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_embeddings(df, main_embeddings, context_embeddings, learning_rate, debug=False):\n",
    "    \n",
    "    #get differences between main embeddings and corresponding context embeddings\n",
    "    main_embeddings_center = main_embeddings.loc[df.center_word].values\n",
    "    context_embeddings_context = context_embeddings.loc[df.context_word].values\n",
    "    diffs = context_embeddings_context - main_embeddings_center\n",
    "    \n",
    "    #get similarities, scores, and errors between main embeddings and corresponding context embeddings\n",
    "    dot_prods = np.sum(main_embeddings_center * context_embeddings_context, axis=1)\n",
    "    scores = sigmoid(dot_prods)\n",
    "    errors = (df.label - scores).values.reshape(-1,1)\n",
    "    \n",
    "    #calculate updates\n",
    "    updates = diffs*errors*learning_rate\n",
    "    updates_df = pd.DataFrame(data=updates)\n",
    "    updates_df['center_word'] = df.center_word\n",
    "    updates_df['context_word'] = df.context_word\n",
    "    updates_df_center = updates_df.groupby('center_word').sum()\n",
    "    updates_df_context = updates_df.groupby('context_word').sum()\n",
    "    \n",
    "    if debug:\n",
    "        plot_words(debug)\n",
    "    \n",
    "    #apply updates\n",
    "    main_embeddings += updates_df_center.loc[main_embeddings.index]\n",
    "    context_embeddings -= updates_df_context.loc[context_embeddings.index]\n",
    "    \n",
    "    #normalize embeddings\n",
    "    main_embeddings = normalize_data(main_embeddings)\n",
    "    context_embeddings = normalize_data(context_embeddings)\n",
    "    \n",
    "    #return the updated embeddings\n",
    "    return main_embeddings, context_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "c52aeef6-3da6-4625-8bcf-0db93e1bfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    row_norms = np.sqrt((data.values**2).sum(axis=1)).reshape(-1,1)\n",
    "    return data.divide(row_norms, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "c915be1b-1105-435c-8682-da9698d8419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_words(debug):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    lim_main_first = main_embeddings.loc[[debug[0]]]\n",
    "    lim_main_second = main_embeddings.loc[[debug[1]]]\n",
    "    p1 = plt.scatter(lim_main_first[0], lim_main_first[1], color='r')\n",
    "    plt.arrow(0,0,float(lim_main_first[0]), float(lim_main_first[1]), head_width=0.01, length_includes_head=True)\n",
    "    for idx,row in lim_main_first.iterrows():\n",
    "        plt.text(row[0], row[1], str(idx))\n",
    "    p2 = plt.scatter(lim_main_second[0], lim_main_second[1], color='r')\n",
    "    plt.arrow(0,0,float(lim_main_second[0]), float(lim_main_second[1]), head_width=0.01, length_includes_head=True)\n",
    "    for idx,row in lim_main_second.iterrows():\n",
    "        plt.text(row[0], row[1], str(idx))\n",
    "    sim = 1 - cosine(main_embeddings.loc[debug[0]], main_embeddings.loc[debug[1]])\n",
    "    plt.title('Sim = %s'%round(sim,4), fontsize=20)\n",
    "    plt.axvline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    t = np.arange(0, 3.14*2+0.1, 0.1)\n",
    "    plt.plot(np.cos(t), np.sin(t), linewidth=1, color='k', alpha=0.5, linestyle='--')\n",
    "    \n",
    "    ###################################\n",
    "    plt.subplot(1,2,2)\n",
    "    lim_main = main_embeddings.loc[[debug[0]]]\n",
    "    lim_context = context_embeddings.loc[[debug[1]]]\n",
    "    p1 = plt.scatter(lim_main[0], lim_main[1], color='r')\n",
    "    plt.arrow(0,0,float(lim_main[0]), float(lim_main[1]), head_width=0.01, length_includes_head=True)\n",
    "    for idx,row in lim_main.iterrows():\n",
    "        plt.text(row[0], row[1], str(idx))\n",
    "    p2 = plt.scatter(lim_context[0], lim_context[1], color='b')\n",
    "    plt.arrow(0,0,float(lim_context[0]), float(lim_context[1]), head_width=0.01, length_includes_head=True)\n",
    "    for idx,row in lim_context.iterrows():\n",
    "        plt.text(row[0], row[1], str(idx))\n",
    "    sim = 1 - cosine(main_embeddings.loc[debug[0]], context_embeddings.loc[debug[1]])\n",
    "    plt.title('Sim = %s'%round(sim,4), fontsize=20)\n",
    "    plt.axvline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.plot(np.cos(t), np.sin(t), linewidth=1, color='k', alpha=0.5, linestyle='--')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "9badb4f3-acb7-4714-979b-651fdaa91613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run until all pairs shown have similarity scores of 1.0 or stop when one gender has over x words\n",
    "EMBEDDING_SIZE = 2\n",
    "\n",
    "main_embeddings = np.random.normal(0,0.1,(len(words), EMBEDDING_SIZE))\n",
    "row_norms = np.sqrt((main_embeddings**2).sum(axis=1)).reshape(-1,1)\n",
    "main_embeddings = main_embeddings / row_norms\n",
    "\n",
    "context_embeddings = np.random.normal(0,0.1,(len(words), EMBEDDING_SIZE))\n",
    "row_norms = np.sqrt((context_embeddings**2).sum(axis=1)).reshape(-1,1)\n",
    "context_embeddings = context_embeddings / row_norms\n",
    "\n",
    "main_embeddings = pd.DataFrame(data=main_embeddings, index=words)\n",
    "context_embeddings = pd.DataFrame(data=context_embeddings, index=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "45bf441e-0312-4f11-9e1f-1ef636acf5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('femininity', 'bias', 0.99),\n",
       " ('femininity', 'characters', 0.99),\n",
       " ('femininity', 'indicatesthat', 0.98),\n",
       " ('femininity', 'article', 0.97),\n",
       " ('femininity', 'desire', 0.97),\n",
       " ('femininity', 'reflected', 0.97)]"
      ]
     },
     "execution_count": 1031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run until all pairs shown have similarity scores of 1.0, stop after running x times or after 2x amount of words reach similarity score for one gender\n",
    "L = []\n",
    "restraints = ['he', 'son', 'his', 'him', 'father', 'man', 'boy', 'himself', 'male', 'brother', 'sons', 'fathers', 'men', 'boys', 'males', 'brothers', \n",
    "'uncle', 'uncles',  'nephew', 'nephews', 'gentleman', 'grandfather', 'sir', 'lord', 'mr.', 'mister', 'husband', 'fiance', 'groom', 'patriarch',\n",
    "'lad', 'chap', 'bloke', 'dude', 'guy', 'fellow', 'stag', 'bull', 'stallion', 'monk', 'masculine', 'boyfriend', 'handsome', 'king', 'prince', 'god', \n",
    "'chief', 'manly', 'duke', 'emperor', 'sire', 'huntsman', 'wizard', 'bishop', 'manager', 'buisnessman', 'hero', 'masculinity']\n",
    "for w1 in words:\n",
    "    for w2 in words:\n",
    "        if w1 != w2:\n",
    "            sim = 1 - cosine(main_embeddings.loc[w1], main_embeddings.loc[w2])\n",
    "            if w2 not in restraints:\n",
    "                L.append((w1,w2,round(sim, 2)))\n",
    "            #top [:x] similar words\n",
    "            #word must be in text enough times\n",
    "            #omit spaces/hyphens\n",
    "sorted([item for item in L if item[0] == 'femininity'], key=lambda t: -t[2])[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "6c5561dd-b1d6-42e2-bf2a-7aa7d985be2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('masculinity', 'used', 1.0),\n",
       " ('masculinity', 'usedby', 1.0),\n",
       " ('masculinity', 'role', 0.96),\n",
       " ('masculinity', 'literature', 0.95),\n",
       " ('masculinity', 'thescarcity', 0.88),\n",
       " ('masculinity', 'vital', 0.87)]"
      ]
     },
     "execution_count": 1032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop after running x times or after 2x amount of words reach similarity score for one gender\n",
    "L = []\n",
    "restraints = ['femme', 'she', 'daughter', 'hers', 'her', 'mother', 'woman', 'girl', 'herself', 'female', 'sister', 'daughters', 'mothers', 'women',\n",
    "'girls', 'females', 'sisters', 'aunt', 'aunts', 'niece', 'nieces', 'grandmother', 'miss', 'ms.', 'madam', 'fiancee', 'bride', 'matriarch', 'gentleness', \n",
    "'sisterhood', 'sorority', 'feminine', 'girlfriend', 'quenn', 'princess', 'goddess', 'diva', 'maiden', 'dame', 'matron', 'heroine', 'muse', 'womanhood',\n",
    "'femininity', 'buisnesswoman', 'actress', 'manageress', 'ladylike', 'girlish', 'beautiful', 'femininity']\n",
    "for w1 in words:\n",
    "    for w2 in words:\n",
    "        if w1 != w2:\n",
    "            sim = 1 - cosine(main_embeddings.loc[w1], main_embeddings.loc[w2])\n",
    "            if w2 not in restraints:\n",
    "                L.append((w1,w2,round(sim, 2)))\n",
    "            #top [:x] similar words\n",
    "            #word must be in text enough times\n",
    "            #omit spaces/hyphens\n",
    "sorted([item for item in L if item[0] == 'masculinity'], key=lambda t: -t[2])[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b690b7-2ea7-4afb-8f9f-bbc81231d1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
